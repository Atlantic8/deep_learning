{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "batch_size = 256\n",
    "epoch = 30\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST('dataset', train=True, download=True, \n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.1307,), (0.3081,))\n",
    "                       ])),\n",
    "        batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST('dataset', train=False, transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.1307,), (0.3081,))\n",
    "                       ])),\n",
    "        batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, \n",
    "    dilation=1, groups=1, bias=True, padding_mode='zeros')\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # input: 1,28*28\n",
    "        self.conv1 = nn.Conv2d(1, 10, 5) # \n",
    "        self.conv2 = nn.Conv2d(10, 20, 3)\n",
    "        self.fc1 = nn.Linear(20*10*10, 500)\n",
    "        self.fc2 = nn.Linear(500, 10)\n",
    "    def forward(self, x):\n",
    "        \"\"\"x: 1,28*28\n",
    "        \"\"\"\n",
    "        in_size = x.size(0)\n",
    "        # 1,28*28 -> 10, 24*24 -> 10, 24*24 -> 10, 12*12\n",
    "        out = F.max_pool2d(F.relu(self.conv1(x)), 2, 2)\n",
    "        # 10, 12*12 -> 20, 10*10 -> 20, 10*10\n",
    "        out = F.relu(self.conv2(out))\n",
    "        \n",
    "        out = out.view(in_size, -1)\n",
    "        # 20, 10*10 -> 500 -> 10\n",
    "        out = self.fc2(F.relu(self.fc1(out)))\n",
    "        out = F.log_softmax(out, dim=1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvNet().to(device)\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (batch_idx+1) % 30 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()\n",
    "            pred = output.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [14848/60000 (25%)]\tLoss: 0.026057\n",
      "Train Epoch: 1 [30208/60000 (50%)]\tLoss: 0.017528\n",
      "Train Epoch: 1 [45568/60000 (75%)]\tLoss: 0.045409\n",
      "\n",
      "Test set: Average loss: 0.0296, Accuracy: 9907/10000 (99%)\n",
      "\n",
      "Train Epoch: 2 [14848/60000 (25%)]\tLoss: 0.013430\n",
      "Train Epoch: 2 [30208/60000 (50%)]\tLoss: 0.008060\n",
      "Train Epoch: 2 [45568/60000 (75%)]\tLoss: 0.014223\n",
      "\n",
      "Test set: Average loss: 0.0341, Accuracy: 9890/10000 (99%)\n",
      "\n",
      "Train Epoch: 3 [14848/60000 (25%)]\tLoss: 0.009545\n",
      "Train Epoch: 3 [30208/60000 (50%)]\tLoss: 0.021086\n",
      "Train Epoch: 3 [45568/60000 (75%)]\tLoss: 0.032012\n",
      "\n",
      "Test set: Average loss: 0.0291, Accuracy: 9906/10000 (99%)\n",
      "\n",
      "Train Epoch: 4 [14848/60000 (25%)]\tLoss: 0.016935\n",
      "Train Epoch: 4 [30208/60000 (50%)]\tLoss: 0.008823\n",
      "Train Epoch: 4 [45568/60000 (75%)]\tLoss: 0.018348\n",
      "\n",
      "Test set: Average loss: 0.0292, Accuracy: 9912/10000 (99%)\n",
      "\n",
      "Train Epoch: 5 [14848/60000 (25%)]\tLoss: 0.004490\n",
      "Train Epoch: 5 [30208/60000 (50%)]\tLoss: 0.009725\n",
      "Train Epoch: 5 [45568/60000 (75%)]\tLoss: 0.003877\n",
      "\n",
      "Test set: Average loss: 0.0269, Accuracy: 9918/10000 (99%)\n",
      "\n",
      "Train Epoch: 6 [14848/60000 (25%)]\tLoss: 0.004767\n",
      "Train Epoch: 6 [30208/60000 (50%)]\tLoss: 0.005468\n",
      "Train Epoch: 6 [45568/60000 (75%)]\tLoss: 0.013691\n",
      "\n",
      "Test set: Average loss: 0.0325, Accuracy: 9888/10000 (99%)\n",
      "\n",
      "Train Epoch: 7 [14848/60000 (25%)]\tLoss: 0.007242\n",
      "Train Epoch: 7 [30208/60000 (50%)]\tLoss: 0.016875\n",
      "Train Epoch: 7 [45568/60000 (75%)]\tLoss: 0.010835\n",
      "\n",
      "Test set: Average loss: 0.0323, Accuracy: 9907/10000 (99%)\n",
      "\n",
      "Train Epoch: 8 [14848/60000 (25%)]\tLoss: 0.005705\n",
      "Train Epoch: 8 [30208/60000 (50%)]\tLoss: 0.003471\n",
      "Train Epoch: 8 [45568/60000 (75%)]\tLoss: 0.002670\n",
      "\n",
      "Test set: Average loss: 0.0303, Accuracy: 9913/10000 (99%)\n",
      "\n",
      "Train Epoch: 9 [14848/60000 (25%)]\tLoss: 0.001212\n",
      "Train Epoch: 9 [30208/60000 (50%)]\tLoss: 0.007746\n",
      "Train Epoch: 9 [45568/60000 (75%)]\tLoss: 0.002358\n",
      "\n",
      "Test set: Average loss: 0.0349, Accuracy: 9899/10000 (99%)\n",
      "\n",
      "Train Epoch: 10 [14848/60000 (25%)]\tLoss: 0.001052\n",
      "Train Epoch: 10 [30208/60000 (50%)]\tLoss: 0.002471\n",
      "Train Epoch: 10 [45568/60000 (75%)]\tLoss: 0.002894\n",
      "\n",
      "Test set: Average loss: 0.0337, Accuracy: 9917/10000 (99%)\n",
      "\n",
      "Train Epoch: 11 [14848/60000 (25%)]\tLoss: 0.002154\n",
      "Train Epoch: 11 [30208/60000 (50%)]\tLoss: 0.003215\n",
      "Train Epoch: 11 [45568/60000 (75%)]\tLoss: 0.002136\n",
      "\n",
      "Test set: Average loss: 0.0304, Accuracy: 9911/10000 (99%)\n",
      "\n",
      "Train Epoch: 12 [14848/60000 (25%)]\tLoss: 0.001703\n",
      "Train Epoch: 12 [30208/60000 (50%)]\tLoss: 0.000463\n",
      "Train Epoch: 12 [45568/60000 (75%)]\tLoss: 0.004062\n",
      "\n",
      "Test set: Average loss: 0.0335, Accuracy: 9918/10000 (99%)\n",
      "\n",
      "Train Epoch: 13 [14848/60000 (25%)]\tLoss: 0.001488\n",
      "Train Epoch: 13 [30208/60000 (50%)]\tLoss: 0.006820\n",
      "Train Epoch: 13 [45568/60000 (75%)]\tLoss: 0.000945\n",
      "\n",
      "Test set: Average loss: 0.0357, Accuracy: 9910/10000 (99%)\n",
      "\n",
      "Train Epoch: 14 [14848/60000 (25%)]\tLoss: 0.001981\n",
      "Train Epoch: 14 [30208/60000 (50%)]\tLoss: 0.001428\n",
      "Train Epoch: 14 [45568/60000 (75%)]\tLoss: 0.005034\n",
      "\n",
      "Test set: Average loss: 0.0372, Accuracy: 9908/10000 (99%)\n",
      "\n",
      "Train Epoch: 15 [14848/60000 (25%)]\tLoss: 0.000594\n",
      "Train Epoch: 15 [30208/60000 (50%)]\tLoss: 0.000689\n",
      "Train Epoch: 15 [45568/60000 (75%)]\tLoss: 0.000926\n",
      "\n",
      "Test set: Average loss: 0.0393, Accuracy: 9905/10000 (99%)\n",
      "\n",
      "Train Epoch: 16 [14848/60000 (25%)]\tLoss: 0.001598\n",
      "Train Epoch: 16 [30208/60000 (50%)]\tLoss: 0.007671\n",
      "Train Epoch: 16 [45568/60000 (75%)]\tLoss: 0.003225\n",
      "\n",
      "Test set: Average loss: 0.0416, Accuracy: 9904/10000 (99%)\n",
      "\n",
      "Train Epoch: 17 [14848/60000 (25%)]\tLoss: 0.001610\n",
      "Train Epoch: 17 [30208/60000 (50%)]\tLoss: 0.022111\n",
      "Train Epoch: 17 [45568/60000 (75%)]\tLoss: 0.002041\n",
      "\n",
      "Test set: Average loss: 0.0451, Accuracy: 9902/10000 (99%)\n",
      "\n",
      "Train Epoch: 18 [14848/60000 (25%)]\tLoss: 0.020082\n",
      "Train Epoch: 18 [30208/60000 (50%)]\tLoss: 0.009383\n",
      "Train Epoch: 18 [45568/60000 (75%)]\tLoss: 0.006037\n",
      "\n",
      "Test set: Average loss: 0.0392, Accuracy: 9910/10000 (99%)\n",
      "\n",
      "Train Epoch: 19 [14848/60000 (25%)]\tLoss: 0.000604\n",
      "Train Epoch: 19 [30208/60000 (50%)]\tLoss: 0.001607\n",
      "Train Epoch: 19 [45568/60000 (75%)]\tLoss: 0.000170\n",
      "\n",
      "Test set: Average loss: 0.0340, Accuracy: 9924/10000 (99%)\n",
      "\n",
      "Train Epoch: 20 [14848/60000 (25%)]\tLoss: 0.000388\n",
      "Train Epoch: 20 [30208/60000 (50%)]\tLoss: 0.000127\n",
      "Train Epoch: 20 [45568/60000 (75%)]\tLoss: 0.000490\n",
      "\n",
      "Test set: Average loss: 0.0342, Accuracy: 9930/10000 (99%)\n",
      "\n",
      "Train Epoch: 21 [14848/60000 (25%)]\tLoss: 0.000250\n",
      "Train Epoch: 21 [30208/60000 (50%)]\tLoss: 0.001691\n",
      "Train Epoch: 21 [45568/60000 (75%)]\tLoss: 0.000092\n",
      "\n",
      "Test set: Average loss: 0.0343, Accuracy: 9921/10000 (99%)\n",
      "\n",
      "Train Epoch: 22 [14848/60000 (25%)]\tLoss: 0.000210\n",
      "Train Epoch: 22 [30208/60000 (50%)]\tLoss: 0.000074\n",
      "Train Epoch: 22 [45568/60000 (75%)]\tLoss: 0.000051\n",
      "\n",
      "Test set: Average loss: 0.0335, Accuracy: 9927/10000 (99%)\n",
      "\n",
      "Train Epoch: 23 [14848/60000 (25%)]\tLoss: 0.000126\n",
      "Train Epoch: 23 [30208/60000 (50%)]\tLoss: 0.000074\n",
      "Train Epoch: 23 [45568/60000 (75%)]\tLoss: 0.000066\n",
      "\n",
      "Test set: Average loss: 0.0343, Accuracy: 9928/10000 (99%)\n",
      "\n",
      "Train Epoch: 24 [14848/60000 (25%)]\tLoss: 0.000057\n",
      "Train Epoch: 24 [30208/60000 (50%)]\tLoss: 0.000068\n",
      "Train Epoch: 24 [45568/60000 (75%)]\tLoss: 0.000035\n",
      "\n",
      "Test set: Average loss: 0.0350, Accuracy: 9928/10000 (99%)\n",
      "\n",
      "Train Epoch: 25 [14848/60000 (25%)]\tLoss: 0.000024\n",
      "Train Epoch: 25 [30208/60000 (50%)]\tLoss: 0.000019\n",
      "Train Epoch: 25 [45568/60000 (75%)]\tLoss: 0.000040\n",
      "\n",
      "Test set: Average loss: 0.0354, Accuracy: 9928/10000 (99%)\n",
      "\n",
      "Train Epoch: 26 [14848/60000 (25%)]\tLoss: 0.000022\n",
      "Train Epoch: 26 [30208/60000 (50%)]\tLoss: 0.000015\n",
      "Train Epoch: 26 [45568/60000 (75%)]\tLoss: 0.000025\n",
      "\n",
      "Test set: Average loss: 0.0361, Accuracy: 9928/10000 (99%)\n",
      "\n",
      "Train Epoch: 27 [14848/60000 (25%)]\tLoss: 0.000052\n",
      "Train Epoch: 27 [30208/60000 (50%)]\tLoss: 0.000064\n",
      "Train Epoch: 27 [45568/60000 (75%)]\tLoss: 0.000034\n",
      "\n",
      "Test set: Average loss: 0.0368, Accuracy: 9928/10000 (99%)\n",
      "\n",
      "Train Epoch: 28 [14848/60000 (25%)]\tLoss: 0.000023\n",
      "Train Epoch: 28 [30208/60000 (50%)]\tLoss: 0.000037\n",
      "Train Epoch: 28 [45568/60000 (75%)]\tLoss: 0.000026\n",
      "\n",
      "Test set: Average loss: 0.0367, Accuracy: 9928/10000 (99%)\n",
      "\n",
      "Train Epoch: 29 [14848/60000 (25%)]\tLoss: 0.000021\n",
      "Train Epoch: 29 [30208/60000 (50%)]\tLoss: 0.000026\n",
      "Train Epoch: 29 [45568/60000 (75%)]\tLoss: 0.000035\n",
      "\n",
      "Test set: Average loss: 0.0368, Accuracy: 9928/10000 (99%)\n",
      "\n",
      "Train Epoch: 30 [14848/60000 (25%)]\tLoss: 0.000013\n",
      "Train Epoch: 30 [30208/60000 (50%)]\tLoss: 0.000013\n",
      "Train Epoch: 30 [45568/60000 (75%)]\tLoss: 0.000011\n",
      "\n",
      "Test set: Average loss: 0.0370, Accuracy: 9931/10000 (99%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, epoch + 1):\n",
    "    train(model, device, train_loader, optimizer, epoch)\n",
    "    test(model, device, test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch for Deeplearning",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
